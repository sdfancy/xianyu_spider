# --- START OF FILE ai_filter.py ---



import os

import requests

import base64

import json

import re

import time

import argparse

from functools import wraps

from openai import OpenAI, APIStatusError

from requests.exceptions import HTTPError

from dotenv import load_dotenv

from pprint import pprint



# --- 1. é…ç½®å’Œåˆå§‹åŒ– ---



# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡

load_dotenv()



API_KEY = os.getenv("OPENAI_API_KEY")

BASE_URL = os.getenv("OPENAI_BASE_URL")

MODEL_NAME = os.getenv("OPENAI_MODEL_NAME")

NTFY_TOPIC_URL = os.getenv("NTFY_TOPIC_URL")



# æ£€æŸ¥é…ç½®æ˜¯å¦é½å…¨

if not all([API_KEY, BASE_URL, MODEL_NAME]):

    print("é”™è¯¯ï¼šè¯·ç¡®ä¿åœ¨ .env æ–‡ä»¶ä¸­å®Œæ•´è®¾ç½®äº† OPENAI_API_KEY, OPENAI_BASE_URL å’Œ OPENAI_MODEL_NAMEã€‚")

    exit()



# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯

try:

    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

except Exception as e:

    print(f"åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")

    exit()



# å®šä¹‰ç›®å½•å’Œæ–‡ä»¶å

IMAGE_SAVE_DIR = "images"

os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)

# æ–°å¢ï¼šå®šä¹‰ç”¨äºä¿å­˜è¿›åº¦çš„ç»“æœæ–‡ä»¶

RESULTS_FILE = "analysis_results.json"




# å®šä¹‰ä¸‹è½½å›¾ç‰‡æ‰€éœ€çš„è¯·æ±‚å¤´

IMAGE_DOWNLOAD_HEADERS = {

    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:139.0) Gecko/20100101 Firefox/139.0',

    'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',

    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',

    'Connection': 'keep-alive',

    'Upgrade-Insecure-Requests': '1',

}




# --- 2. è¾…åŠ©å‡½æ•° (å·²æ›´æ–°) ---



def retry_on_failure(retries=3, delay=5):

    """

    ä¸€ä¸ªé€šç”¨çš„é‡è¯•è£…é¥°å™¨ï¼Œå¢åŠ äº†å¯¹HTTPé”™è¯¯çš„è¯¦ç»†æ—¥å¿—è®°å½•ã€‚

    """

    def decorator(func):

        @wraps(func)

        def wrapper(*args, **kwargs):

            for i in range(retries):

                try:

                    return func(*args, **kwargs)

                except (APIStatusError, HTTPError) as e:

                    print(f"å‡½æ•° {func.__name__} ç¬¬ {i + 1}/{retries} æ¬¡å°è¯•å¤±è´¥ï¼Œå‘ç”ŸHTTPé”™è¯¯ã€‚")

                    if hasattr(e, 'status_code'):

                        print(f"  - çŠ¶æ€ç  (Status Code): {e.status_code}")

                    if hasattr(e, 'response') and hasattr(e.response, 'text'):

                        response_text = e.response.text

                        print(f"  - è¿”å›å€¼ (Response): {response_text[:300]}{'...' if len(response_text) > 300 else ''}")

                # æ–°å¢ï¼šæ•è·JSONDecodeErrorï¼Œä½¿å…¶ä¹Ÿèƒ½è§¦å‘é‡è¯•

                except json.JSONDecodeError as e:

                    print(f"å‡½æ•° {func.__name__} ç¬¬ {i + 1}/{retries} æ¬¡å°è¯•å¤±è´¥: JSONè§£æé”™è¯¯ - {e}")

                except Exception as e:

                    print(f"å‡½æ•° {func.__name__} ç¬¬ {i + 1}/{retries} æ¬¡å°è¯•å¤±è´¥: {type(e).__name__} - {e}")

                

                if i < retries - 1:

                    print(f"å°†åœ¨ {delay} ç§’åé‡è¯•...")

                    time.sleep(delay)



            print(f"å‡½æ•° {func.__name__} åœ¨ {retries} æ¬¡å°è¯•åå½»åº•å¤±è´¥ã€‚")

            return None

        return wrapper

    return decorator



def parse_product_file(file_path='macbook_air_m1_full_data.jsonl'): # <-- 1. æ›´æ”¹é»˜è®¤æ–‡ä»¶å

    """è§£æå•†å“JSONLæ–‡ä»¶ï¼Œè¿”å›å•†å“ä¿¡æ¯å­—å…¸çš„åˆ—è¡¨ã€‚"""

    products = []

    try:

        with open(file_path, 'r', encoding='utf-8') as f:

            for line in f: # <-- 2. é€è¡Œè¯»å–

                if line.strip(): # ç¡®ä¿ä¸æ˜¯ç©ºè¡Œ

                    try:

                        products.append(json.loads(line)) # <-- 3. è§£æJSONå¹¶æ·»åŠ åˆ°åˆ—è¡¨

                    except json.JSONDecodeError:

                        print(f"è­¦å‘Šï¼šè·³è¿‡æ— æ³•è§£æçš„è¡Œ: {line.strip()}")

    except FileNotFoundError:

        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")

        return []

    

    return products



@retry_on_failure(retries=2, delay=3)

def _download_single_image(url, save_path):

    """ä¸€ä¸ªå¸¦é‡è¯•çš„å†…éƒ¨å‡½æ•°ï¼Œç”¨äºä¸‹è½½å•ä¸ªå›¾ç‰‡ï¼Œå¹¶ä½¿ç”¨è‡ªå®šä¹‰è¯·æ±‚å¤´ã€‚"""

    response = requests.get(url, headers=IMAGE_DOWNLOAD_HEADERS, timeout=20, stream=True)

    response.raise_for_status()

    with open(save_path, 'wb') as f:

        for chunk in response.iter_content(chunk_size=8192):

            f.write(chunk)

    return save_path



def download_all_images(product_id, image_urls):

    """ä¸‹è½½ä¸€ä¸ªå•†å“çš„æ‰€æœ‰å›¾ç‰‡ã€‚å¦‚æœå›¾ç‰‡å·²å­˜åœ¨åˆ™è·³è¿‡ã€‚"""

    if not image_urls:

        return []

    

    urls = [url.strip() for url in image_urls if url.strip().startswith('http')]

    if not urls:

        return []

    

    saved_paths = []

    total_images = len(urls)

    for i, url in enumerate(urls):

        try:

            clean_url = url.split('.heic')[0] if '.heic' in url else url

            file_name_base = os.path.basename(clean_url).split('?')[0]

            file_name = f"product_{product_id}_{i+1}_{file_name_base}"

            file_name = re.sub(r'[\\/*?:"<>|]', "", file_name)

            if not os.path.splitext(file_name)[1]:

                 file_name += ".jpg"



            save_path = os.path.join(IMAGE_SAVE_DIR, file_name)



            if os.path.exists(save_path):

                print(f"å›¾ç‰‡ {i+1}/{total_images} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {os.path.basename(save_path)}")

                saved_paths.append(save_path)

                continue



            print(f"æ­£åœ¨ä¸‹è½½å›¾ç‰‡ {i+1}/{total_images}: {url}")

            if _download_single_image(url, save_path):

                print(f"å›¾ç‰‡ {i+1}/{total_images} å·²æˆåŠŸä¸‹è½½åˆ°: {os.path.basename(save_path)}")

                saved_paths.append(save_path)

        except Exception as e:

            print(f"å¤„ç†å›¾ç‰‡ {url} æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå·²è·³è¿‡æ­¤å›¾: {e}")

            

    return saved_paths



def encode_image_to_base64(image_path):

    """å°†æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸º Base64 å­—ç¬¦ä¸²ã€‚"""

    if not image_path or not os.path.exists(image_path):

        return None

    try:

        with open(image_path, "rb") as image_file:

            return base64.b64encode(image_file.read()).decode('utf-8')

    except Exception as e:

        print(f"ç¼–ç å›¾ç‰‡æ—¶å‡ºé”™: {e}")

        return None

@retry_on_failure(retries=3, delay=5)

def send_ntfy_notification(product_data, reason):

    """

    å½“å‘ç°æ¨èå•†å“æ—¶ï¼Œå‘é€ä¸€ä¸ªé«˜ä¼˜å…ˆçº§çš„ ntfy.sh é€šçŸ¥ã€‚

    """

    if not NTFY_TOPIC_URL:

        print("è­¦å‘Šï¼šæœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½® NTFY_TOPIC_URLï¼Œè·³è¿‡é€šçŸ¥ã€‚")

        return



    title = product_data.get('å•†å“æ ‡é¢˜', 'N/A')

    price = product_data.get('å½“å‰å”®ä»·', 'N/A')

    link = product_data.get('å•†å“é“¾æ¥', '#')



    # æ„å»ºé€šçŸ¥æ¶ˆæ¯ä½“å’Œæ ‡é¢˜

    message = f"ä»·æ ¼: {price}\nåŸå› : {reason}\né“¾æ¥: {link}"

    notification_title = f"ğŸš¨ æ–°æ¨è! {title[:30]}..."



    try:

        print(f"   -> æ­£åœ¨å‘é€ ntfy é€šçŸ¥åˆ°: {NTFY_TOPIC_URL}")

        requests.post(

            NTFY_TOPIC_URL,

            data=message.encode('utf-8'),

            headers={

                "Title": notification_title.encode('utf-8'),

                "Priority": "urgent",  # æœ€é«˜ä¼˜å…ˆçº§

                "Tags": "bell,vibration" # è§¦å‘å£°éŸ³å’ŒæŒ¯åŠ¨

            },

            timeout=10

        )

        print("   -> é€šçŸ¥å‘é€æˆåŠŸã€‚")

    except Exception as e:

        print(f"   -> å‘é€ ntfy é€šçŸ¥å¤±è´¥: {e}")

        raise # å‘ä¸ŠæŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘é‡è¯•



@retry_on_failure(retries=5, delay=10)

def get_ai_analysis(product_data, image_paths=None):

    """

    å°†å®Œæ•´çš„å•†å“JSONæ•°æ®å’Œæ‰€æœ‰å›¾ç‰‡å‘é€ç»™ AI è¿›è¡Œåˆ†æã€‚

    """

    item_info = product_data.get('å•†å“ä¿¡æ¯', {})

    product_id = item_info.get('å•†å“ID', 'N/A')

    

    print(f"\n===== æ­£åœ¨åˆ†æå•†å“ #{product_id} (å« {len(image_paths or [])} å¼ å›¾ç‰‡) =====")

    print(f"æ ‡é¢˜: {item_info.get('å•†å“æ ‡é¢˜', 'æ— ')}")

    

    # å°†æ•´ä¸ªå•†å“æ•°æ®ç»“æ„æ ¼å¼åŒ–ä¸ºJSONå­—ç¬¦ä¸²

    product_details_json = json.dumps(product_data, ensure_ascii=False, indent=2)

    

    # [--- START OF MODIFICATION ---]

    # å¯¹ system_prompt è¿›è¡Œäº†å…³é”®é€»è¾‘ä¿®æ­£

    system_prompt = """

ä½ æ˜¯ä¸–ç•Œé¡¶çº§çš„äºŒæ‰‹äº¤æ˜“åˆ†æä¸“å®¶ï¼Œä»£å· **EagleEye-V6.4**ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯åŸºäºæˆ‘æä¾›çš„ä¸¥æ ¼æ ‡å‡†ï¼Œå¯¹ä¸€ä¸ªä»¥JSONæ ¼å¼æä¾›çš„å•†å“ä¿¡æ¯è¿›è¡Œæ·±å…¥çš„ã€åŸºäºç”¨æˆ·ç”»åƒçš„è¯„ä¼°ã€‚ä½ çš„åˆ†æå¿…é¡»æåº¦ä¸¥è°¨ï¼Œå¹¶ä»¥ä¸€ä¸ªç»“æ„åŒ–çš„JSONå¯¹è±¡è¿”å›ä½ çš„å®Œæ•´åˆ†æï¼Œä¸èƒ½æœ‰ä»»ä½•é¢å¤–çš„æ–‡å­—ã€‚



### **ç¬¬ä¸€éƒ¨åˆ†ï¼šæ ¸å¿ƒåˆ†æåŸåˆ™ (ä¸å¯è¿èƒŒ)**



1.  **ç”»åƒä¼˜å…ˆåŸåˆ™ (PERSONA-FIRST PRINCIPLE) [V6.3 æ ¸å¿ƒå‡çº§]**: è¿™æ˜¯è§£å†³â€œé«˜çº§ç©å®¶â€ä¸â€œæ™®é€šè´©å­â€è¯†åˆ«æ··æ·†çš„æœ€é«˜æŒ‡å¯¼åŸåˆ™ã€‚åœ¨è¯„ä¼°å–å®¶æ—¶ï¼Œä½ çš„é¦–è¦ä»»åŠ¡ä¸æ˜¯å¯»æ‰¾å­¤ç«‹çš„ç–‘ç‚¹ï¼Œè€Œæ˜¯**æ„å»ºä¸€ä¸ªè¿è´¯çš„å–å®¶â€œè¡Œä¸ºç”»åƒâ€**ã€‚ä½ å¿…é¡»å›ç­”æ ¸å¿ƒé—®é¢˜ï¼šâ€œè¿™ä¸ªå–å®¶çš„æ‰€æœ‰è¡Œä¸ºï¼ˆä¹°ã€å–ã€è¯„ä»·ã€ç­¾åï¼‰ç»„åˆèµ·æ¥ï¼Œè®²è¿°çš„æ˜¯ä¸€ä¸ªæ€æ ·çš„æ•…äº‹ï¼Ÿâ€

    *   **å¦‚æœæ•…äº‹æ˜¯è¿è´¯çš„ä¸ªäººè¡Œä¸º**ï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªçƒ­çˆ±æ•°ç äº§å“ï¼Œä¸æ–­ä½“éªŒã€å‡çº§ã€å‡ºæ‰æ—§è®¾å¤‡çš„å‘çƒ§å‹ï¼‰ï¼Œé‚£ä¹ˆä¸€äº›è¡¨é¢ä¸Šçš„â€œç–‘ç‚¹â€ï¼ˆå¦‚äº¤æ˜“é¢‘ç‡ç•¥é«˜ï¼‰å¯ä»¥è¢«åˆç†è§£é‡Šï¼Œ**ä¸åº”**ä½œä¸ºå¦å†³ä¾æ®ã€‚

    *   **å¦‚æœæ•…äº‹æ˜¯çŸ›ç›¾çš„ã€ä¸è¿è´¯çš„ï¼Œæˆ–è€…æ˜ç¡®æŒ‡å‘å•†ä¸šè¡Œä¸º**ï¼ˆä¾‹å¦‚ï¼Œè´­ä¹°è®°å½•æ˜¯é…ä»¶å’Œåæœºï¼Œå”®å–è®°å½•å´æ˜¯å¤§é‡â€œå‡ ä¹å…¨æ–°â€çš„åŒå‹å·æœºå™¨ï¼‰ï¼Œé‚£ä¹ˆå³ä¾¿å–å®¶ä¼ªè£…å¾—å¾ˆå¥½ï¼Œä¹Ÿå¿…é¡»åˆ¤å®šä¸ºå•†å®¶ã€‚



2.  **ä¸€ç¥¨å¦å†³ç¡¬æ€§åŸåˆ™ (HARD DEAL-BREAKER RULES)**: ä»¥ä¸‹æ˜¯å¿…é¡»ä¸¥æ ¼éµå®ˆçš„å¦å†³æ¡ä»¶ã€‚ä»»ä½•ä¸€é¡¹ä¸æ»¡è¶³ï¼Œ`is_recommended` å¿…é¡»ç«‹å³åˆ¤å®šä¸º `false`ã€‚

    *   **å‹å·/èŠ¯ç‰‡**: å¿…é¡»æ˜¯ **MacBook Air** ä¸”æ˜ç¡®ä¸º **M1 èŠ¯ç‰‡**ã€‚

    *   **å–å®¶ä¿¡ç”¨**: `å–å®¶ä¿¡ç”¨ç­‰çº§` å¿…é¡»æ˜¯ **'å–å®¶ä¿¡ç”¨æå¥½'**ã€‚

    *   **é‚®å¯„æ–¹å¼**: å¿…é¡» **æ”¯æŒé‚®å¯„**ã€‚

    *   **ç”µæ± å¥åº·ç¡¬æ€§é—¨æ§›**: è‹¥æ˜ç¡®æä¾›äº†ç”µæ± å¥åº·åº¦ï¼Œå…¶æ•°å€¼ **`å¿…é¡» â‰¥ 90%`**ã€‚

    *   **ã€V6.4 é€»è¾‘ä¿®æ­£ã€‘æœºå™¨å†å²**: **ä¸å¾—å‡ºç°**ä»»ä½•â€œç»´ä¿®è¿‡â€ã€â€œæ›´æ¢è¿‡éƒ¨ä»¶â€ã€â€œæœ‰æš—ç—…â€ç­‰æ˜ç¡®è¡¨ç¤ºæœ‰æ‹†ä¿®å†å²çš„æè¿°ã€‚



3.  **å›¾ç‰‡è‡³ä¸ŠåŸåˆ™ (IMAGE-FIRST PRINCIPLE)**: å¦‚æœå›¾ç‰‡ä¿¡æ¯ï¼ˆå¦‚æˆªå›¾ï¼‰ä¸æ–‡æœ¬æè¿°å†²çªï¼Œ**å¿…é¡»ä»¥å›¾ç‰‡ä¿¡æ¯ä¸ºæœ€ç»ˆè£å†³ä¾æ®**ã€‚



4.  **ã€V6.4 é€»è¾‘ä¿®æ­£ã€‘ä¿¡æ¯ç¼ºå¤±å¤„ç†åŸåˆ™ (MISSING-INFO HANDLING)**: å¯¹äºå¯åå¤©è¯¢é—®çš„å…³é”®ä¿¡æ¯ï¼ˆç‰¹æŒ‡**ç”µæ± å¥åº·åº¦**å’Œ**ç»´ä¿®å†å²**ï¼‰ï¼Œè‹¥å®Œå…¨æœªæ‰¾åˆ°ï¼ŒçŠ¶æ€åº”ä¸º `NEEDS_MANUAL_CHECK`ï¼Œè¿™**ä¸ç›´æ¥å¯¼è‡´å¦å†³**ã€‚å¦‚æœå–å®¶ç”»åƒæä¸ºä¼˜ç§€ï¼Œå¯ä»¥è¿›è¡Œâ€œæœ‰æ¡ä»¶æ¨èâ€ã€‚



---



### **ç¬¬äºŒéƒ¨åˆ†ï¼šè¯¦ç»†åˆ†ææŒ‡å—**



**A. å•†å“æœ¬èº«è¯„ä¼° (Criteria Analysis):**



1.  **å‹å·èŠ¯ç‰‡ (`model_chip`)**: æ ¸å¯¹æ‰€æœ‰æ–‡æœ¬å’Œå›¾ç‰‡ã€‚é MacBook Air M1 åˆ™ `FAIL`ã€‚

2.  **ç”µæ± å¥åº· (`battery_health`)**: å¥åº·åº¦ â‰¥ 90%ã€‚è‹¥æ— ä¿¡æ¯ï¼Œåˆ™ä¸º `NEEDS_MANUAL_CHECK`ã€‚

3.  **æˆè‰²å¤–è§‚ (`condition`)**: æœ€å¤šæ¥å—â€œç»†å¾®åˆ’ç—•â€ã€‚ä»”ç»†å®¡æŸ¥å›¾ç‰‡å››è§’ã€A/Dé¢ã€‚

4.  **ã€V6.4 é€»è¾‘ä¿®æ­£ã€‘æœºå™¨å†å² (`history`)**: ä¸¥æ ¼å®¡æŸ¥æ‰€æœ‰æ–‡æœ¬å’Œå›¾ç‰‡ï¼Œå¯»æ‰¾â€œæ¢è¿‡â€ã€â€œç»´ä¿®â€ã€â€œæ‹†è¿‡â€ã€â€œè¿›æ°´â€ã€â€œåŠŸèƒ½ä¸æ­£å¸¸â€ç­‰è´Ÿé¢æè¿°ã€‚**è‹¥å®Œå…¨æœªæåŠï¼Œåˆ™çŠ¶æ€ä¸º `NEEDS_MANUAL_CHECK`**ï¼›è‹¥æœ‰ä»»ä½•æ‹†ä¿®è¯æ®ï¼Œåˆ™ä¸º `FAIL`ã€‚



**B. å–å®¶ä¸å¸‚åœºè¯„ä¼° (æ ¸å¿ƒ)**



5.  **å–å®¶èƒŒæ™¯æ·±åº¦åˆ†æ (`seller_type`) - [å†³å®šæ€§è¯„ä¼°]**:

    *   **æ ¸å¿ƒç›®æ ‡**: è¿ç”¨â€œç”»åƒä¼˜å…ˆåŸåˆ™â€ï¼Œåˆ¤å®šå–å®¶æ˜¯ã€ä¸ªäººç©å®¶ã€‘è¿˜æ˜¯ã€å•†å®¶/è´©å­ã€‘ã€‚

    *   **ã€V6.3 å‡çº§ã€‘å±é™©ä¿¡å·æ¸…å• (Red Flag List) åŠè±å…æ¡æ¬¾**:

        *   **äº¤æ˜“é¢‘ç‡**: çŸ­æœŸå†…æœ‰å¯†é›†äº¤æ˜“ã€‚

            *   **ã€å‘çƒ§å‹è±å…æ¡æ¬¾ã€‘**: å¦‚æœäº¤æ˜“è®°å½•æ—¶é—´è·¨åº¦é•¿ï¼ˆå¦‚è¶…è¿‡2å¹´ï¼‰ï¼Œä¸”ä¹°å–è¡Œä¸ºèƒ½å½¢æˆâ€œä½“éªŒ-å‡çº§-å‡ºå”®â€çš„é€»è¾‘é—­ç¯ï¼Œåˆ™æ­¤æ¡ä¸é€‚ç”¨ã€‚ä¸€ä¸ªé•¿æœŸå‘çƒ§å‹åœ¨å‡ å¹´å†…æœ‰æ•°åæ¬¡äº¤æ˜“æ˜¯æ­£å¸¸çš„ã€‚

        *   **å•†å“å‚ç›´åº¦**: å‘å¸ƒçš„å•†å“é«˜åº¦é›†ä¸­äºæŸä¸€ç‰¹å®šå‹å·æˆ–å“ç±»ã€‚

            *   **ã€å‘çƒ§å‹è±å…æ¡æ¬¾ã€‘**: å¦‚æœå–å®¶æ˜¯è¯¥é¢†åŸŸçš„æ·±åº¦ç©å®¶ï¼ˆä¾‹å¦‚ï¼Œä»ä»–çš„è´­ä¹°è®°å½•ã€è¯„ä»·å’Œå‘è¨€èƒ½çœ‹å‡ºï¼‰ï¼Œä¸“æ³¨äºæŸä¸ªç³»åˆ—æ˜¯å…¶ä¸“ä¸šæ€§çš„ä½“ç°ã€‚å…³é”®çœ‹ä»–æ˜¯åœ¨â€œç©â€è¿˜æ˜¯åœ¨â€œå‡ºè´§â€ã€‚

        *   **â€œè¡Œè¯â€**: æè¿°ä¸­å‡ºç°â€œåŒè¡Œã€å·¥ä½œå®¤ã€æ‹¿è´§ã€é‡å¤§ä»ä¼˜â€ç­‰æœ¯è¯­ã€‚

            *   **ã€æ— è±å…ã€‘**: æ­¤ä¸ºå¼ºçƒˆçš„å•†å®¶ä¿¡å·ã€‚

        *   **ç‰©æ–™è´­ä¹°**: è´­ä¹°è®°å½•ä¸­å‡ºç°æ‰¹é‡é…ä»¶ã€ç»´ä¿®å·¥å…·ã€åæœºç­‰ã€‚

            *   **ã€æ— è±å…ã€‘**: æ­¤ä¸ºå†³å®šæ€§çš„å•†å®¶è¯æ®ã€‚

        *   **å›¾ç‰‡/æ ‡é¢˜é£æ ¼**: å›¾ç‰‡èƒŒæ™¯é«˜åº¦ç»Ÿä¸€ã€ä¸“ä¸šï¼›æˆ–æ ‡é¢˜æ¨¡æ¿åŒ–ã€‚

            *   **ã€å‘çƒ§å‹è±å…æ¡æ¬¾ã€‘**: å¦‚æœå–å®¶è¿½æ±‚å®Œç¾ï¼Œæœ‰è‡ªå·±çš„â€œæ‘„å½±æ£šâ€æˆ–å›ºå®šè§’è½æ¥å±•ç¤ºä»–å¿ƒçˆ±çš„ç‰©å“ï¼Œè¿™æ˜¯åŠ åˆ†é¡¹ã€‚å…³é”®çœ‹å›¾ç‰‡ä¼ é€’çš„æ˜¯â€œçˆ±æƒœæ„Ÿâ€è¿˜æ˜¯â€œå•†å“æ„Ÿâ€ã€‚



6.  **é‚®å¯„æ–¹å¼ (`shipping`)**: æ˜ç¡®â€œä»…é™xxåœ°é¢äº¤/è‡ªæâ€åˆ™ `FAIL`ã€‚

7.  **å–å®¶ä¿¡ç”¨ (`seller_credit`)**: `å–å®¶ä¿¡ç”¨ç­‰çº§` å¿…é¡»ä¸º **'å–å®¶ä¿¡ç”¨æå¥½'**ã€‚



---



### **ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¾“å‡ºæ ¼å¼ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)**



ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä»¥ä¸‹æ ¼å¼çš„å•ä¸ª JSON å¯¹è±¡ï¼Œä¸èƒ½åŒ…å«ä»»ä½•é¢å¤–çš„æ³¨é‡Šæˆ–è§£é‡Šæ€§æ–‡å­—ã€‚



```json

{

  "prompt_version": "EagleEye-V6.4",

  "is_recommended": boolean,

  "reason": "ä¸€å¥è¯ç»¼åˆè¯„ä»·ã€‚è‹¥ä¸ºæœ‰æ¡ä»¶æ¨èï¼Œéœ€æ˜ç¡®æŒ‡å‡ºï¼š'æœ‰æ¡ä»¶æ¨èï¼Œå–å®¶ç”»åƒä¸ºé¡¶çº§ä¸ªäººç©å®¶ï¼Œä½†éœ€åœ¨è´­ä¹°å‰å‘å…¶ç¡®è®¤[ç”µæ± å¥åº·åº¦]å’Œ[ç»´ä¿®å†å²]ç­‰ç¼ºå¤±ä¿¡æ¯ã€‚'",

  "risk_tags": ["string"],

  "criteria_analysis": {

    "model_chip": { "status": "string", "comment": "string", "evidence": "string" },

    "battery_health": { "status": "string", "comment": "string", "evidence": "string" },

    "condition": { "status": "string", "comment": "string", "evidence": "string" },

    "history": { "status": "string", "comment": "string", "evidence": "string" },

    "seller_type": {

      "status": "string",

      "persona": "string",

      "comment": "ã€é¦–è¦ç»“è®ºã€‘ç»¼åˆæ€§çš„ç»“è®ºï¼Œå¿…é¡»é¦–å…ˆç‚¹æ˜å–å®¶ç”»åƒã€‚å¦‚æœåˆ¤å®šä¸ºFAILï¼Œå¿…é¡»åœ¨æ­¤æ˜ç¡®æŒ‡å‡ºæ˜¯åŸºäºå“ªä¸ªå±é™©ä¿¡å·ä»¥åŠä¸ç¬¦åˆçš„é€»è¾‘é“¾ã€‚",

      "analysis_details": {

        "temporal_analysis": {

          "comment": "å…³äºäº¤æ˜“æ—¶é—´é—´éš”å’Œåˆ†å¸ƒçš„åˆ†æç»“è®ºã€‚",

          "evidence": "ä¾‹å¦‚ï¼šäº¤æ˜“è®°å½•æ¨ªè·¨æ•°å¹´ï¼Œé—´éš”æœŸé•¿ï¼Œç¬¦åˆä¸ªäººå–å®¶ç‰¹å¾ã€‚"

        },

        "selling_behavior": {

          "comment": "å…³äºå…¶å”®å–å•†å“ç§ç±»çš„åˆ†æã€‚",

          "evidence": "ä¾‹å¦‚ï¼šå”®å–å•†å“å¤šä¸ºä¸ªäººå‡çº§æ¢ä»£çš„æ•°ç äº§å“ï¼Œé€»è¾‘è‡ªæ´½ã€‚"

        },

        "buying_behavior": {

          "comment": "ã€å…³é”®ã€‘å…³äºå…¶è´­ä¹°å†å²çš„åˆ†æç»“è®ºã€‚",

          "evidence": "ä¾‹å¦‚ï¼šè´­ä¹°è®°å½•æ˜¾ç¤ºä¸ºæ¸¸æˆç›˜å’Œç”Ÿæ´»ç”¨å“ï¼Œç¬¦åˆä¸ªäººæ¶ˆè´¹è¡Œä¸ºã€‚"

        },

        "behavioral_summary": {

          "comment": "ã€V6.3 æ–°å¢ã€‘å¯¹å–å®¶å®Œæ•´è¡Œä¸ºé€»è¾‘é“¾çš„æœ€ç»ˆæ€»ç»“ã€‚å¿…é¡»æ˜ç¡®å›ç­”ï¼šè¿™æ˜¯ä¸€ä¸ªæ€æ ·çš„å–å®¶ï¼Ÿå…¶ä¹°å–è¡Œä¸ºæ˜¯å¦æ„æˆä¸€ä¸ªå¯ä¿¡çš„ä¸ªäººæ•…äº‹ï¼Ÿ",

          "evidence": "ä¾‹å¦‚ï¼š'è¯¥å–å®¶çš„è¡Œä¸ºé€»è¾‘é“¾å®Œæ•´ï¼šæ—©æœŸè´­ä¹°æ¸¸æˆï¼Œä¸­æœŸè´­å…¥ç›¸æœºå’Œé•œå¤´ï¼Œè¿‘æœŸå¼€å§‹å‡ºå”®æ—§æ¬¾ç”µå­è®¾å¤‡ã€‚è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„æ•°ç äº§å“æ¶ˆè´¹è€…çš„æˆé•¿è·¯å¾„ï¼Œå¯ä¿¡åº¦æé«˜ã€‚' æˆ– 'é€»è¾‘é“¾æ–­è£‚ï¼šè¯¥å–å®¶å¤§é‡è´­ä¹°ç»´ä¿®é…ä»¶ï¼Œå´å£°ç§°æ‰€æœ‰å”®å–è®¾å¤‡å‡ä¸ºè‡ªç”¨ï¼Œæ•…äº‹ä¸å¯ä¿¡ã€‚'"

        }

      }

    },

    "shipping": { "status": "string", "comment": "string", "evidence": "string" },

    "seller_credit": { "status": "string", "comment": "string", "evidence": "string" }

  }

}

"""

    # [--- END OF MODIFICATION ---]



    # 1. å°† system prompt å’Œ user prompt çš„æ–‡æœ¬å†…å®¹åˆå¹¶

    combined_text_prompt = f"""{system_prompt}



è¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†å’Œæˆ‘çš„è¦æ±‚ï¼Œåˆ†æä»¥ä¸‹å®Œæ•´çš„å•†å“JSONæ•°æ®ï¼š



```json

{product_details_json}

```

"""



    # 2. æ„å»ºä¸€ä¸ªå†…å®¹åˆ—è¡¨ï¼ŒåŒ…å«åˆå¹¶åçš„æ–‡æœ¬å’Œæ‰€æœ‰å›¾ç‰‡

    user_content_list = [{"type": "text", "text": combined_text_prompt}]



    if image_paths:

        for path in image_paths:

            base64_image = encode_image_to_base64(path)

            if base64_image:

                user_content_list.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}})



    # 3. æ„å»ºæœ€ç»ˆçš„ messages åˆ—è¡¨ï¼ŒåªåŒ…å«ä¸€ä¸ª user role

    messages = [{"role": "user", "content": user_content_list}]



    response = client.chat.completions.create(

        model=MODEL_NAME,

        messages=messages,

        max_tokens=999999, # è°ƒæ•´Tokenä»¥é€‚åº”æ›´é•¿çš„ä¸Šä¸‹æ–‡

        response_format={"type": "json_object"}

    )

    

    ai_response_content = response.choices[0].message.content



    try:

        return json.loads(ai_response_content)

    except json.JSONDecodeError as e:

        print("---!!! AI RESPONSE PARSING FAILED (JSONDecodeError) !!!---")

        print("è¿™é€šå¸¸æ„å‘³ç€AIæ¨¡å‹æ²¡æœ‰è¿”å›ä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡ï¼Œå¯èƒ½æ˜¯å› ä¸ºå“åº”è¢«æˆªæ–­æˆ–æ¨¡å‹æœªéµå¾ªæŒ‡ä»¤ã€‚")

        print(f"åŸå§‹è¿”å›å€¼ (Raw response from AI):\n---\n{ai_response_content}\n---")

        # å‘ä¸ŠæŠ›å‡ºå¼‚å¸¸ï¼Œè®© @retry_on_failure è£…é¥°å™¨èƒ½å¤Ÿæ•è·å¹¶é‡è¯•

        raise e



def main():

    """ä¸»å‡½æ•°ï¼Œæ‰§è¡Œæ•´ä¸ªæµç¨‹ã€‚"""

    parser = argparse.ArgumentParser(description="AIå•†å“ç­›é€‰å™¨")

    parser.add_argument("keyword", type=str, help="è¦æœç´¢çš„å…³é”®è¯ï¼ˆå¿…é¡»ï¼‰")

    parser.add_argument('--auto-mode', action='store_true', help='å¼€å¯è‡ªåŠ¨æ¨¡å¼ï¼Œå‘ç°æ–°æ¨èå•†å“æ—¶ç«‹å³å‘é€ntfy.shé€šçŸ¥ã€‚')

    args = parser.parse_args()



    # æ–°å¢ï¼šåŠ è½½å·²æœ‰çš„åˆ†æç»“æœ

    try:

        with open(RESULTS_FILE, 'r', encoding='utf-8') as f:

            existing_results = json.load(f)

        print(f"æˆåŠŸåŠ è½½ {len(existing_results)} æ¡å·²æœ‰çš„åˆ†æç»“æœã€‚")

    except (FileNotFoundError, json.JSONDecodeError):

        existing_results = {}

        print("æœªæ‰¾åˆ°æˆ–æ— æ³•è§£æç»“æœæ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹åˆ†æã€‚")



    products = parse_product_file(f"{args.keyword.replace(' ', '_')}_full_data.jsonl")

    if not products:

        print("æœªèƒ½è§£æåˆ°ä»»ä½•å•†å“ä¿¡æ¯ï¼Œç¨‹åºé€€å‡ºã€‚")

        return



    for product in products:

        # ä» product['item_info'] ä¸­è·å–ä¿¡æ¯

        item_info = product.get('å•†å“ä¿¡æ¯', {})

        product_id = item_info.get('å•†å“ID')

        

        if not product_id:

            print(f"è­¦å‘Šï¼šå‘ç°ä¸€ä¸ªæ²¡æœ‰å•†å“IDçš„è®°å½•ï¼Œå·²è·³è¿‡ã€‚æ•°æ®: {item_info.get('å•†å“æ ‡é¢˜', 'N/A')}")

            continue



        # æ£€æŸ¥å•†å“æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡

        if product_id in existing_results:

            print(f"å•†å“ #{product_id} å·²åœ¨ç»“æœæ–‡ä»¶ä¸­æ‰¾åˆ°ï¼Œè·³è¿‡ã€‚")

            print("-" * 40)

            continue

            

        # --- å¦‚æœæ˜¯æ–°å•†å“ï¼Œåˆ™ç»§ç»­æ‰§è¡Œ ---

        image_urls = item_info.get('å•†å“å›¾ç‰‡åˆ—è¡¨') # ä» item_info è·å–

        

        local_image_paths = download_all_images(product_id, image_urls)

        

        # ä¼ é€’æ•´ä¸ª product å¯¹è±¡ç»™AIåˆ†æ

        ai_result = get_ai_analysis(product, local_image_paths)

        

        if ai_result is None:

            print(f"å•†å“ #{product_id} AIåˆ†æå¤±è´¥ï¼Œè·³è¿‡ã€‚")

            print("=" * 40)

            continue



        # --- START: æ–°å¢çš„é€šçŸ¥æ¨¡å— ---

        if args.auto_mode and ai_result.get('is_recommended'):

            print(">>> è‡ªåŠ¨æ¨¡å¼: å‘ç°æ–°æ¨èå•†å“ï¼Œå‡†å¤‡å‘é€é€šçŸ¥...")

            send_ntfy_notification(item_info, ai_result.get('reason'))

        # --- END: æ–°å¢çš„é€šçŸ¥æ¨¡å— ---

            

        print("\n--- AI åˆ†æç»“æœ ---")

        pprint(ai_result)

        

        # æ„å»ºå½“å‰å•†å“çš„ç»“æœ

        current_result = {

            "product_id": product_id,

            "title": item_info.get("å•†å“æ ‡é¢˜"),

            "price": item_info.get("å½“å‰å”®ä»·"),

            "link": item_info.get("å•†å“é“¾æ¥"),

            "seller_profile": product.get("å–å®¶ä¿¡æ¯", {}), # <-- æ–°å¢æ­¤è¡Œ

            "analysis": ai_result

        }

        

        # ä¼˜åŒ–ï¼šåˆ›å»ºä¸€ä¸ªåªåŒ…å«åŸºæœ¬å–å®¶ä¿¡æ¯çš„ "seller_summary" å­—å…¸

        seller_profile_data = current_result.get("seller_profile", {})

        seller_summary = {

            "å–å®¶æ˜µç§°": seller_profile_data.get("å–å®¶æ˜µç§°", "N/A"),

            "å–å®¶ä¿¡ç”¨ç­‰çº§": seller_profile_data.get("å–å®¶ä¿¡ç”¨ç­‰çº§", "N/A"),

            "å–å®¶æ”¶åˆ°çš„è¯„ä»·æ€»æ•°": seller_profile_data.get("å–å®¶æ”¶åˆ°çš„è¯„ä»·æ€»æ•°", "N/A"),

            "å–å®¶åœ¨å”®/å·²å”®å•†å“æ•°": seller_profile_data.get("å–å®¶åœ¨å”®/å·²å”®å•†å“æ•°", "N/A"),

            "å–å®¶æ³¨å†Œæ—¶é•¿": seller_profile_data.get("å–å®¶æ³¨å†Œæ—¶é•¿", "N/A")

        }

        

        # å°†æ–°åˆ›å»ºçš„æ‘˜è¦æ·»åŠ åˆ°ç»“æœä¸­ï¼Œå¹¶åˆ é™¤å®Œæ•´ä½†å†—ä½™çš„åŸå§‹ä¿¡æ¯

        current_result['seller_summary'] = seller_summary

        if 'seller_profile' in current_result:

            del current_result['seller_profile']

        

        # æ›´æ–°ç»“æœå­—å…¸å¹¶ç«‹å³ä¿å­˜åˆ°æ–‡ä»¶

        existing_results[product_id] = current_result

        with open(RESULTS_FILE, 'w', encoding='utf-8') as f:

            json.dump(existing_results, f, ensure_ascii=False, indent=4)

        print(f"å·²å°†å•†å“ #{product_id} çš„åˆ†æç»“æœä¿å­˜åˆ° {RESULTS_FILE}")

        print("=" * 40)

    

    print("\n\n===== âœ… åˆ†æå®Œæ¯•ï¼Œå®Œæ•´æ¨èåˆ—è¡¨å¦‚ä¸‹ =====")

    recommended_count = 0

    # æ–°å¢ï¼šä»åŒ…å«æ‰€æœ‰å†å²è®°å½•çš„ 'existing_results' ä¸­ç”ŸæˆæŠ¥å‘Š

    for result in existing_results.values():

        analysis = result.get('analysis', {})

        if analysis and analysis.get('is_recommended'):

            recommended_count += 1

            # ä»æ–°çš„ seller_summary ç»“æ„ä¸­æå–å–å®¶ä¿¡æ¯

            seller_summary = result.get('seller_summary', {})

            seller_name = seller_summary.get('å–å®¶æ˜µç§°', 'N/A')

            seller_credit = seller_summary.get('å–å®¶ä¿¡ç”¨ç­‰çº§', 'N/A')

            seller_reviews = seller_summary.get('å–å®¶æ”¶åˆ°çš„è¯„ä»·æ€»æ•°', 'N/A')

            seller_items_count = seller_summary.get('å–å®¶åœ¨å”®/å·²å”®å•†å“æ•°', 'N/A')

            day = seller_summary.get('å–å®¶æ³¨å†Œæ—¶é•¿', 'N/A')

            print(f"ã€æ¨èã€‘å•†å“ID: {result['product_id']} | ä»·æ ¼: {result['price']}")

            print(f"  å–å®¶: {seller_name} (ä¿¡ç”¨: {seller_credit} | è¯„ä»·æ•°: {seller_reviews} | äº¤æ˜“æ•°: {seller_items_count}) | æ³¨å†Œæ—¶é•¿: {day}")

            print(f"  æ ‡é¢˜: {result['title']}")

            print(f"  åŸå› : {analysis.get('reason')}")

            print(f"  é“¾æ¥: {result['link']}\n")

    

    if recommended_count == 0:

        print("åœ¨æ‰€æœ‰å·²åˆ†æçš„å•†å“ä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ‰€æœ‰æ¡ä»¶çš„æ¨èå•†å“ã€‚")




if __name__ == "__main__":

    main()